{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d8e0604-11da-4617-baed-3ea73fb367f4",
   "metadata": {},
   "source": [
    "# **Preprocessing and Modeling**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ad287d-9ec0-457e-a784-c738e131b9a0",
   "metadata": {},
   "source": [
    "#### *Imports and Read in Data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "935ff38c-29d6-495f-93ee-206570641323",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, classification_report, f1_score, precision_score \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "06744e24-2600-42bc-b40a-b491bce0f79e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>author</th>\n",
       "      <th>selftext</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>author_premium</th>\n",
       "      <th>is_video</th>\n",
       "      <th>score</th>\n",
       "      <th>title</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>post_char_length</th>\n",
       "      <th>post_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Jay_Subabove</td>\n",
       "      <td>This batter is hitting .191 with 3HR, 12 RBI, ...</td>\n",
       "      <td>1655862592</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>Am I crazy?</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>263</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Stress_Factor</td>\n",
       "      <td>Not a Yankees fan, but modern day record looki...</td>\n",
       "      <td>1655856890</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>MLB Record (Wins)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subreddit         author  \\\n",
       "0          0   Jay_Subabove   \n",
       "1          0  Stress_Factor   \n",
       "\n",
       "                                            selftext  created_utc  \\\n",
       "0  This batter is hitting .191 with 3HR, 12 RBI, ...   1655862592   \n",
       "1  Not a Yankees fan, but modern day record looki...   1655856890   \n",
       "\n",
       "  author_premium  is_video  score              title  upvote_ratio  \\\n",
       "0          False     False      1        Am I crazy?           1.0   \n",
       "1          False     False      1  MLB Record (Wins)           1.0   \n",
       "\n",
       "   num_comments  post_char_length  post_word_count  \n",
       "0             0               263               53  \n",
       "1             0                96               19  "
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit = pd.read_csv('../data/reddit_cleaned.csv')\n",
    "reddit.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf59609-c9e1-4d21-be07-fe083130d50b",
   "metadata": {},
   "source": [
    "------\n",
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "3a488dac-ecb7-4032-acec-4b3f2e5324ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using a function to remove html which seemed to be scattered throughout based on EDA\n",
    "# this code was adapted from the breakfast hour NLP practice for week 5\n",
    "\n",
    "def remove_html(post):\n",
    "    '''function to remove html and lowercase all text'''\n",
    "    post = post.lower()\n",
    "    no_html = BeautifulSoup(post).text\n",
    "    \n",
    "    return no_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "355ac86f-5939-400b-b247-56590bd0c48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/petermurphy/opt/anaconda3/envs/dsi/lib/python3.9/site-packages/bs4/__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/Users/petermurphy/opt/anaconda3/envs/dsi/lib/python3.9/site-packages/bs4/__init__.py:404: MarkupResemblesLocatorWarning: The input looks more like a URL than markup. You may want to use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>author</th>\n",
       "      <th>selftext</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>author_premium</th>\n",
       "      <th>is_video</th>\n",
       "      <th>score</th>\n",
       "      <th>title</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>post_char_length</th>\n",
       "      <th>post_word_count</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Jay_Subabove</td>\n",
       "      <td>This batter is hitting .191 with 3HR, 12 RBI, ...</td>\n",
       "      <td>1655862592</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>Am I crazy?</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>263</td>\n",
       "      <td>53</td>\n",
       "      <td>this batter is hitting .191 with 3hr, 12 rbi, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Stress_Factor</td>\n",
       "      <td>Not a Yankees fan, but modern day record looki...</td>\n",
       "      <td>1655856890</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>MLB Record (Wins)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>19</td>\n",
       "      <td>not a yankees fan, but modern day record looki...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subreddit         author  \\\n",
       "0          0   Jay_Subabove   \n",
       "1          0  Stress_Factor   \n",
       "\n",
       "                                            selftext  created_utc  \\\n",
       "0  This batter is hitting .191 with 3HR, 12 RBI, ...   1655862592   \n",
       "1  Not a Yankees fan, but modern day record looki...   1655856890   \n",
       "\n",
       "  author_premium  is_video  score              title  upvote_ratio  \\\n",
       "0          False     False      1        Am I crazy?           1.0   \n",
       "1          False     False      1  MLB Record (Wins)           1.0   \n",
       "\n",
       "   num_comments  post_char_length  post_word_count  \\\n",
       "0             0               263               53   \n",
       "1             0                96               19   \n",
       "\n",
       "                                          clean_text  \n",
       "0  this batter is hitting .191 with 3hr, 12 rbi, ...  \n",
       "1  not a yankees fan, but modern day record looki...  "
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit['clean_text'] = reddit['selftext'].apply(remove_html)\n",
    "reddit.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "b8fdd10c-8016-47de-a91f-5fbc691bce27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating functions that stem and lemmatize text - to be used as hyperparameters\n",
    "# this code was adapted from the breakfast hour NLP practice for week 5\n",
    "# lemmatize first\n",
    "\n",
    "def lemmatize_post(post):\n",
    "    '''\n",
    "    Function splits the text data,\n",
    "    lemmatizes it, and rejoins\n",
    "    '''\n",
    "    post_split = post.split()\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    return \" \".join([lemmatizer.lemmatize(word) for word in post_split])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "54988e2b-d9c7-4589-9bea-93de5cd729cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now for stemming\n",
    "\n",
    "def stem_post(post):\n",
    "    '''Same framework applied as lemmatize'''\n",
    "    post_split = post.split()\n",
    "    p_stemmer = PorterStemmer()\n",
    "    \n",
    "    return \" \".join([p_stemmer.stem(word) for word in post_split])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca464214-9319-4065-8f3e-74636539b120",
   "metadata": {},
   "source": [
    "------\n",
    "## **Modeling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "2379632c-941b-4073-9073-fe23961a4245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# starting with simple models - just text column and default hyperparameters\n",
    "# will tune once there appears to be a pipeline that works best\n",
    "\n",
    "X = reddit['clean_text']\n",
    "y = reddit['subreddit']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdf6ab6-c4c4-49aa-bf33-03bd39a4e1d3",
   "metadata": {},
   "source": [
    "### **Defining the baseline accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "2c42ac7c-55f5-4c38-99d4-d8e51cebe66f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.500198\n",
       "0    0.499802\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4323902-db66-4e7a-a01c-65b538dc5590",
   "metadata": {},
   "source": [
    "*hoping to beat the 51% baseline accuracy* (and ideally hit > 80% as defined in problem statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "25e5a2b4-4a80-41ff-9295-f8e091b5d846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1889,)\n",
      "(630,)\n"
     ]
    }
   ],
   "source": [
    "# splitting the training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f3db4b-beaf-44ac-a1a9-4a9eafff4dd6",
   "metadata": {},
   "source": [
    "#### 1) Count Vectorizer and Naive Bayes (defaults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "e82a796a-f6e4-41e4-909f-1d4a7fc5120e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the pipeline\n",
    "pipe_cnb = Pipeline([\n",
    "    ('cvec',CountVectorizer()),\n",
    "    ('nb',MultinomialNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "5694aa6f-1b2b-417f-ad13-87b7a8fd4931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cvec', CountVectorizer()), ('nb', MultinomialNB())])"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_cnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "a6144eb3-0510-4855-a147-e34cd74da6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.771836950767602\n",
      "Test accuracy: 0.6603174603174603\n"
     ]
    }
   ],
   "source": [
    "print(f'Training accuracy: {pipe_cnb.score(X_train, y_train)}')\n",
    "print(f'Test accuracy: {pipe_cnb.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "4b1a19e7-8da3-417c-9ddc-ca857516d62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# heavily overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "521af173-40ec-489e-9b1a-79c93d97a0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.68      0.67       315\n",
      "           1       0.67      0.64      0.65       315\n",
      "\n",
      "    accuracy                           0.66       630\n",
      "   macro avg       0.66      0.66      0.66       630\n",
      "weighted avg       0.66      0.66      0.66       630\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = pipe_cnb.predict(X_test)\n",
    "\n",
    "# print the classification report after generating predictions\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "bdd698af-9f9b-4b9f-a501-af302378eb4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test score: 0.6603174603174603\n",
      "F1 Score: 0.6525974025974025\n",
      "Precision Score: 0.6677740863787376\n"
     ]
    }
   ],
   "source": [
    "print(f'test score: {pipe_cnb.score(X_test, y_test)}')\n",
    "print(f'F1 Score: {f1_score(y_test, preds)}')\n",
    "print(f'Precision Score: {precision_score(y_test, preds)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc9949a-e24a-4e93-9796-065212f79746",
   "metadata": {},
   "source": [
    "#### 2) Tfidf Vectorizer and Naive Bayes (defaults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "da473de3-ca45-4729-8ed0-84aaa1dc163f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.7723663313922711\n",
      "Test accuracy: 0.6682539682539682\n"
     ]
    }
   ],
   "source": [
    "# repeat the same process to train additional models (again with default parameters)\n",
    "pipe_tnb = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()),\n",
    "    ('nb', MultinomialNB())\n",
    "])\n",
    "\n",
    "pipe_tnb.fit(X_train, y_train)\n",
    "\n",
    "print(f'Training accuracy: {pipe_tnb.score(X_train, y_train)}')\n",
    "print(f'Test accuracy: {pipe_tnb.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "2038f999-a541-4cd0-8fdc-6d0b53ff7e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slightly worse accuracy and heavily overfit like before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "de2e0f2b-f4f0-496c-a8ce-1419098b0ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.70      0.68       315\n",
      "           1       0.68      0.63      0.66       315\n",
      "\n",
      "    accuracy                           0.67       630\n",
      "   macro avg       0.67      0.67      0.67       630\n",
      "weighted avg       0.67      0.67      0.67       630\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = pipe_tnb.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "cd4c229e-eef3-43eb-bca8-60a7627e3d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test score: 0.6682539682539682\n",
      "F1 Score: 0.6556836902800658\n",
      "Precision Score: 0.6815068493150684\n"
     ]
    }
   ],
   "source": [
    "print(f'test score: {pipe_tnb.score(X_test, y_test)}')\n",
    "print(f'F1 Score: {f1_score(y_test, preds)}')\n",
    "print(f'Precision Score: {precision_score(y_test, preds)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ed4562-8c8e-4c01-a6ef-acbe91ae2e03",
   "metadata": {},
   "source": [
    "#### 3) Count Vectorizer and Logistic Regression (defaults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "57748e33-96ab-47d9-8c58-eb659c13d47a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.8941238750661725\n",
      "Test accuracy: 0.726984126984127\n"
     ]
    }
   ],
   "source": [
    "# repeat process with logistic regression\n",
    "pipe_clog = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('log', LogisticRegression())\n",
    "])\n",
    "\n",
    "pipe_clog.fit(X_train, y_train)\n",
    "\n",
    "print(f'Training accuracy: {pipe_clog.score(X_train, y_train)}')\n",
    "print(f'Test accuracy: {pipe_clog.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "773fdf8d-9ba2-4e25-9065-3d5a5b78531b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Still heavily overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "151f1570-c6f2-44dd-b09c-8d1a48336830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.7485380116959065\n",
      "Precision Score: 0.6937669376693767\n",
      " \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.64      0.70       315\n",
      "           1       0.69      0.81      0.75       315\n",
      "\n",
      "    accuracy                           0.73       630\n",
      "   macro avg       0.73      0.73      0.72       630\n",
      "weighted avg       0.73      0.73      0.72       630\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = pipe_clog.predict(X_test)\n",
    "\n",
    "print(f'F1 Score: {f1_score(y_test, preds)}')\n",
    "print(f'Precision Score: {precision_score(y_test, preds)}')\n",
    "print(' ')\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e1f1d2-0466-4232-bf2d-40d8a9805ffd",
   "metadata": {},
   "source": [
    "#### 4) Tfidf  Vectorizer and Logistic Regression (defaults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "3c10a310-d2d6-4ee4-9b87-50abbfc8e3fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.830068819481207\n",
      "Test accuracy: 0.7253968253968254\n"
     ]
    }
   ],
   "source": [
    "# repeat process with logistic regression\n",
    "pipe_tlog = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()),\n",
    "    ('log', LogisticRegression())\n",
    "])\n",
    "\n",
    "pipe_tlog.fit(X_train, y_train)\n",
    "\n",
    "print(f'Training accuracy: {pipe_tlog.score(X_train, y_train)}')\n",
    "print(f'Test accuracy: {pipe_tlog.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "7d127705-1dfa-4816-bdda-ce0f56146418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.7258320126782885\n",
      "Precision Score: 0.7246835443037974\n",
      " \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.72      0.72       315\n",
      "           1       0.72      0.73      0.73       315\n",
      "\n",
      "    accuracy                           0.73       630\n",
      "   macro avg       0.73      0.73      0.73       630\n",
      "weighted avg       0.73      0.73      0.73       630\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# slightly less overfit but still less than ideal\n",
    "preds = pipe_tlog.predict(X_test)\n",
    "\n",
    "print(f'F1 Score: {f1_score(y_test, preds)}')\n",
    "print(f'Precision Score: {precision_score(y_test, preds)}')\n",
    "print(' ')\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ac034a-9383-470d-b4a3-b6bf7956eefb",
   "metadata": {},
   "source": [
    "#### 1a) Count Vectorizer and Naive Bayes (fine tune w GridSearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "e2425275-2a99-4a07-8254-0150c647d527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.734784364196129\n",
      "Best Parameters: {'cvec__max_df': 0.9, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 2), 'cvec__stop_words': 'english'}\n"
     ]
    }
   ],
   "source": [
    "# build the pipeline\n",
    "params_cnb = {\n",
    "    'cvec__max_df': [0.9, 0.95],\n",
    "    'cvec__min_df': [1,3,5,7,9],\n",
    "    'cvec__ngram_range': [(1,1), (1, 2)],\n",
    "    'cvec__stop_words': [None, 'english'],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe_cnb, param_grid=params_cnb, cv =3)\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "# print out best score and best params\n",
    "print(f'Best score: {gs.best_score_}')\n",
    "print(f'Best Parameters: {gs.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "0f86a435-2476-454a-9617-eb454719f203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test score: 0.7\n",
      "F1 Score: 0.7032967032967032\n",
      "Precision Score: 0.6956521739130435\n"
     ]
    }
   ],
   "source": [
    "preds = gs.predict(X_test)\n",
    "print(f'test score: {gs.score(X_test, y_test)}')\n",
    "print(f'F1 Score: {f1_score(y_test, preds)}')\n",
    "print(f'Precision Score: {precision_score(y_test, preds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "3b856417-05dc-46f8-9fab-c2adc191c0b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(X_test, y_test)\n",
    "#also try stopwords, preprocessor (functions created earlier), tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ab48a0-3448-4c15-9da8-0f7b8fe457e9",
   "metadata": {},
   "source": [
    "#### 2a) Tfidf Vectorizer and Naive Bayes (fine tune w GridSearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "a96fb086-8beb-4bda-a366-47fb11e3615a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.755431902490726\n",
      "Best Parameters: {'tvec__max_df': 0.9, 'tvec__min_df': 1, 'tvec__ngram_range': (1, 2), 'tvec__stop_words': 'english'}\n"
     ]
    }
   ],
   "source": [
    "# repeat the same process to train additional models (again with default parameters)\n",
    "pipe_tnb = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()),\n",
    "    ('nb', MultinomialNB())\n",
    "])\n",
    "\n",
    "grid_params = {\n",
    "    'tvec__max_df': [0.9, 0.95],\n",
    "    'tvec__min_df': [1,3,5,7,9],\n",
    "    'tvec__ngram_range': [(1,1), (1, 2)],\n",
    "    'tvec__stop_words': [None, 'english'],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe_tnb, param_grid = grid_params, cv = 3)\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print(f'Best Score: {gs.best_score_}')\n",
    "print(f'Best Parameters: {gs.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "ed0bf805-a89e-444d-93d7-dca1155ed661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test score: 0.7126984126984127\n",
      "F1 Score: 0.717628705148206\n",
      "Precision Score: 0.7055214723926381\n"
     ]
    }
   ],
   "source": [
    "preds = gs.predict(X_test)\n",
    "print(f'test score: {gs.score(X_test, y_test)}')\n",
    "print(f'F1 Score: {f1_score(y_test, preds)}')\n",
    "print(f'Precision Score: {precision_score(y_test, preds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "b00f4681-ce88-43e5-9c3b-db34c78306f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# minor improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9377c2-0418-4910-97cd-d4eecc0ecc00",
   "metadata": {},
   "source": [
    "#### 3a) Count Vectorizer and Logistic Regression (fine tune w GridSearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "f2d2c2dc-d85b-48e2-9be5-adf7bd335872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.7877240256550602\n",
      "Best Parameters: {'cvec__max_df': 0.9, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 1), 'cvec__stop_words': 'english'}\n"
     ]
    }
   ],
   "source": [
    "# repeat process with logistic regression\n",
    "pipe_clog = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('log', LogisticRegression(max_iter = 10000))\n",
    "])\n",
    "\n",
    "clog_params = {\n",
    "    'cvec__max_df': [0.9, 0.95],\n",
    "    'cvec__min_df': [1,3,5,7,9],\n",
    "    'cvec__ngram_range': [(1,1), (1, 2)],\n",
    "    'cvec__stop_words': [None, 'english'],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe_clog,\n",
    "                 param_grid= clog_params,\n",
    "                 cv = 5)\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print(f'Best Score: {gs.best_score_}')\n",
    "print(f'Best Parameters: {gs.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "b7ec98fb-fccf-4635-b5c9-2d6513c881b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test score: 0.7206349206349206\n",
      "F1 Score: 0.7404129793510326\n",
      "Precision Score: 0.6914600550964187\n"
     ]
    }
   ],
   "source": [
    "preds = gs.predict(X_test)\n",
    "print(f'test score: {gs.score(X_test, y_test)}')\n",
    "print(f'F1 Score: {f1_score(y_test, preds)}')\n",
    "print(f'Precision Score: {precision_score(y_test, preds)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361636bc-da02-4a97-844e-6c3f71e1625c",
   "metadata": {},
   "source": [
    "#### 3b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "d915f04b-8d57-48bc-8bba-3bc8d03982b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.7797833073695142\n",
      "Best Parameters: {'cvec__max_features': 5000}\n"
     ]
    }
   ],
   "source": [
    "# try running again\n",
    "pipe_clog = Pipeline([\n",
    "    ('cvec', CountVectorizer(max_df=.9,min_df=1,ngram_range=(1,2), stop_words = 'english')), \n",
    "    ('log', LogisticRegression())\n",
    "])\n",
    "\n",
    "clog_params = {\n",
    "   'cvec__max_features': [2_000, 3_000, 4_000, 5_000],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe_clog,\n",
    "                 param_grid= clog_params,\n",
    "                 cv = 5)\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print(f'Best Score: {gs.best_score_}')\n",
    "print(f'Best Parameters: {gs.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "cbb81fb4-4aaf-40f7-b4a4-7756172dd0e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test score: 0.7238095238095238\n",
      "F1 Score: 0.7441176470588236\n",
      "Precision Score: 0.6931506849315069\n"
     ]
    }
   ],
   "source": [
    "preds = gs.predict(X_test)\n",
    "print(f'test score: {gs.score(X_test, y_test)}')\n",
    "print(f'F1 Score: {f1_score(y_test, preds)}')\n",
    "print(f'Precision Score: {precision_score(y_test, preds)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1782d88-bde5-4efc-92fe-e0126df9c817",
   "metadata": {},
   "source": [
    "#### 3c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "bc7ec0b3-dd66-4874-b4ff-558676988f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "#consider different stopwords to use \n",
    "# Print English stopwords.\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "b8ca175c-e9e1-4c71-b59c-d54cf5ad2f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_list = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "82c85f86-b706-45df-b299-734709eed195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\", 'removed', 'poll', 'https', 'com', 'www', 'reddit']\n"
     ]
    }
   ],
   "source": [
    "new_words = ['removed', 'poll','https','com','www','reddit'] # pulled from EDA section\n",
    "for i in new_words:\n",
    "    stopword_list.append(i)\n",
    "\n",
    "print(stopword_list)\n",
    "stopword_list = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "3ad88c31-429d-429f-999e-4604d31b4f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.7797748866714385\n"
     ]
    }
   ],
   "source": [
    "# try running again\n",
    "pipe_clog = Pipeline([\n",
    "    ('cvec', CountVectorizer(max_df=.9,min_df=1,ngram_range=(1,2))), \n",
    "    ('log', LogisticRegression(max_iter = 10000))\n",
    "])\n",
    "\n",
    "clog_params = {\n",
    "   'cvec__max_features': [2_000, 3_000, 4_000, 5_000],\n",
    "    'cvec__stop_words': [None, stopword_list]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe_clog,\n",
    "                 param_grid= clog_params,\n",
    "                 cv = 5)\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print(f'Best Score: {gs.best_score_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "9b55cd64-0b3e-4f2e-ba44-a6103663cf10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test score: 0.7174603174603175\n",
      "F1 Score: 0.7435158501440923\n",
      "Precision Score: 0.6807387862796834\n"
     ]
    }
   ],
   "source": [
    "preds = gs.predict(X_test)\n",
    "print(f'test score: {gs.score(X_test, y_test)}')\n",
    "print(f'F1 Score: {f1_score(y_test, preds)}')\n",
    "print(f'Precision Score: {precision_score(y_test, preds)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e16b4dc-3fa3-4e63-8bb9-f303ab470512",
   "metadata": {},
   "source": [
    "#### 4a) Tfidf  Vectorizer and Logistic Regression (fine tune w GridSearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "68826b1e-5d8c-4147-992c-c5096eaa2d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.771319218378042\n",
      "Best Parameters: {'tvec__max_df': 0.9, 'tvec__min_df': 9, 'tvec__ngram_range': (1, 2), 'tvec__stop_words': 'english'}\n"
     ]
    }
   ],
   "source": [
    "pipe_tlog = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()),\n",
    "    ('log', LogisticRegression())\n",
    "])\n",
    "\n",
    "tlog_params = {\n",
    "    'tvec__max_df': [0.9, 0.95],\n",
    "    'tvec__min_df': [1,3,5,7,9],\n",
    "    'tvec__ngram_range': [(1,1), (1, 2)],\n",
    "    'tvec__stop_words': [None, 'english'],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe_tlog,\n",
    "                 param_grid=tlog_params,\n",
    "                 cv = 3)\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print(f'Best Score: {gs.best_score_}')\n",
    "print(f'Best Parameters: {gs.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "72782fef-7cd6-4caa-89fe-e0a6e6c9d157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test score: 0.7301587301587301\n",
      "F1 Score: 0.736842105263158\n",
      "Precision Score: 0.7190332326283988\n"
     ]
    }
   ],
   "source": [
    "preds = gs.predict(X_test)\n",
    "print(f'test score: {gs.score(X_test, y_test)}')\n",
    "print(f'F1 Score: {f1_score(y_test, preds)}')\n",
    "print(f'Precision Score: {precision_score(y_test, preds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "d6bfea72-5c4c-45e1-bdce-625876719857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# still not getting close to the 80% threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f998ce49-5338-4319-913c-cff32cae83fa",
   "metadata": {},
   "source": [
    "------\n",
    "## Changing Gears to Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3432b3fa-e870-45cc-82c2-6d6e4676e23c",
   "metadata": {},
   "source": [
    "#### 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "38f0cae2-ff0a-4c66-ac16-c2c605de3c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7204910793146088\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.9,\n",
       " 'cvec__min_df': 5,\n",
       " 'rf__max_depth': 5,\n",
       " 'rf__n_estimators': 200}"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first attempt with CountVectorizer\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "pipe_cvrf = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('rf', RandomForestClassifier(n_estimators=100))\n",
    "]) \n",
    "\n",
    "rf_params = {\n",
    "    'cvec__max_df': [0.9, 0.95],\n",
    "    'cvec__min_df': [1,3,5,7,9],\n",
    "    'rf__n_estimators': [100, 150, 200, 250],\n",
    "    'rf__max_depth': [1, 2, 3, 4, 5]}\n",
    "\n",
    "gs = GridSearchCV(pipe_cvrf, rf_params, cv = 3)\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "9ed0fdd5-0831-46f9-988b-e54bff1dea15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test score: 0.6698412698412698\n",
      "F1 Score: 0.67601246105919\n",
      "Precision Score: 0.6636085626911316\n"
     ]
    }
   ],
   "source": [
    "preds = gs.predict(X_test)\n",
    "print(f'test score: {gs.score(X_test, y_test)}')\n",
    "print(f'F1 Score: {f1_score(y_test, preds)}')\n",
    "print(f'Precision Score: {precision_score(y_test, preds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "ea4fc64b-6dc0-4896-a199-4b51cfa05936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d9a860-a17b-4d47-8cc4-d0d02533901d",
   "metadata": {},
   "source": [
    "#### 5a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "30998366-fee6-47a1-b251-3eb4a985b9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.74643382878677\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__ngram_range': (1, 1), 'cvec__stop_words': 'english'}"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_cvrf = Pipeline([\n",
    "    ('cvec', CountVectorizer(max_df = 0.9, min_df = 9)),\n",
    "    ('rf', RandomForestClassifier(n_estimators=200, max_depth=5))\n",
    "]) \n",
    "\n",
    "rf_params = {\n",
    "    'cvec__ngram_range': [(1,1), (1, 2)],\n",
    "    'cvec__stop_words': [None, 'english']\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe_cvrf, rf_params, cv = 3)\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "3b4f45ff-0781-4b95-9b28-d78c113659ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test score: 0.7111111111111111\n",
      "F1 Score: 0.7064516129032258\n",
      "Precision Score: 0.7180327868852459\n"
     ]
    }
   ],
   "source": [
    "preds = gs.predict(X_test)\n",
    "print(f'test score: {gs.score(X_test, y_test)}')\n",
    "print(f'F1 Score: {f1_score(y_test, preds)}')\n",
    "print(f'Precision Score: {precision_score(y_test, preds)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccaf2ae-26d1-4336-8742-d5c18dc380b7",
   "metadata": {},
   "source": [
    "#### 6) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "77e9daa6-f552-4669-a5f9-7e4bf9e8b391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7241964653729359\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rf__max_depth': 5,\n",
       " 'rf__n_estimators': 200,\n",
       " 'tvec__max_df': 0.9,\n",
       " 'tvec__min_df': 9}"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#try the same setup with tfidf\n",
    "pipe_tvrf = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()),\n",
    "    ('rf', RandomForestClassifier(n_estimators=100))\n",
    "]) \n",
    "\n",
    "rf_params = {\n",
    "    'tvec__max_df': [0.9, 0.95],\n",
    "    'tvec__min_df': [1,3,5,7,9],\n",
    "    'rf__n_estimators': [100, 150, 200, 250],\n",
    "    'rf__max_depth': [1, 2, 3, 4, 5]}\n",
    "\n",
    "gs = GridSearchCV(pipe_tvrf, rf_params, cv = 3)\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "0f7b3109-d2dd-44e7-a61d-e7d3c2beebf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test score: 0.6761904761904762\n",
      "F1 Score: 0.679245283018868\n",
      "Precision Score: 0.6728971962616822\n"
     ]
    }
   ],
   "source": [
    "preds = gs.predict(X_test)\n",
    "print(f'test score: {gs.score(X_test, y_test)}')\n",
    "print(f'F1 Score: {f1_score(y_test, preds)}')\n",
    "print(f'Precision Score: {precision_score(y_test, preds)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d920cced-9d36-4c95-b1e8-88d2edbe7f45",
   "metadata": {},
   "source": [
    "#### 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "b3846025-eac8-446f-af7e-595e2d41f412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.717838847250612\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.9,\n",
       " 'cvec__min_df': 1,\n",
       " 'et__max_depth': 5,\n",
       " 'et__n_estimators': 250}"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# attempt with ExtremelyRandomizeTrees\n",
    "# first attempt with CountVectorizer\n",
    "pipe_cvet = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('et', ExtraTreesClassifier(n_estimators=100))\n",
    "]) \n",
    "\n",
    "et_params = {\n",
    "    'cvec__max_df': [0.9, 0.95],\n",
    "    'cvec__min_df': [1,3,5,7,9],\n",
    "    'et__n_estimators': [100, 150, 200, 250],\n",
    "    'et__max_depth': [1, 2, 3, 4, 5]}\n",
    "\n",
    "gs = GridSearchCV(pipe_cvet, et_params, cv = 3)\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "33648884-a849-4c0d-9473-e0413b9d46cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test score: 0.6634920634920635\n",
      "F1 Score: 0.6357388316151203\n",
      "Precision Score: 0.6928838951310862\n"
     ]
    }
   ],
   "source": [
    "preds = gs.predict(X_test)\n",
    "print(f'test score: {gs.score(X_test, y_test)}')\n",
    "print(f'F1 Score: {f1_score(y_test, preds)}')\n",
    "print(f'Precision Score: {precision_score(y_test, preds)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9eb1ad-b216-40c6-b5d1-1f8329483d42",
   "metadata": {
    "tags": []
   },
   "source": [
    "------\n",
    "## Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d70343-34a7-4d3e-b86e-6616dd26fdeb",
   "metadata": {},
   "source": [
    "#### 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ff69ff-5e4e-499f-b5a1-c3ac9226bebf",
   "metadata": {},
   "source": [
    "*AdaBoostClassifier*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "10d7c8ea-a8f0-4777-b62e-5ef8d7b71fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.755431902490726\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ada__base_estimator__max_depth': 1,\n",
       " 'ada__learning_rate': 0.9,\n",
       " 'ada__n_estimators': 50,\n",
       " 'cvec__max_df': 0.9,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'cvec__stop_words': None}"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try with CountVectorizer\n",
    "ada_cpipe = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('ada', AdaBoostClassifier(base_estimator=DecisionTreeClassifier()))\n",
    "])\n",
    "\n",
    "ada_params = {\n",
    "    'cvec__max_df': [0.9, 0.95],\n",
    "    'cvec__ngram_range': [(1,1), (1, 2)],\n",
    "    'cvec__stop_words': [None, 'english'],\n",
    "    'ada__n_estimators': [50, 100],\n",
    "    'ada__base_estimator__max_depth': [1, 2],\n",
    "    'ada__learning_rate': [.9, 1.0],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(ada_cpipe, param_grid = ada_params, cv = 3)\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "d37db57c-8575-4e73-9dcc-5647a0e2bfe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test score: 0.726984126984127\n",
      "F1 Score: 0.7425149700598802\n",
      "Precision Score: 0.7025495750708215\n"
     ]
    }
   ],
   "source": [
    "preds = gs.predict(X_test)\n",
    "print(f'test score: {gs.score(X_test, y_test)}')\n",
    "print(f'F1 Score: {f1_score(y_test, preds)}')\n",
    "print(f'Precision Score: {precision_score(y_test, preds)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8f8ea1-4aee-4320-b515-2c7887fab73b",
   "metadata": {},
   "source": [
    "#### 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "cbde6a76-4197-4aa3-b2da-f24640256e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7506657918422625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ada__base_estimator__max_depth': 1,\n",
       " 'ada__learning_rate': 0.9,\n",
       " 'ada__n_estimators': 50,\n",
       " 'tvec__max_df': 0.9,\n",
       " 'tvec__ngram_range': (1, 1),\n",
       " 'tvec__stop_words': 'english'}"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try with Tfidf Vectorizer\n",
    "ada_tpipe = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()),\n",
    "    ('ada', AdaBoostClassifier(base_estimator=DecisionTreeClassifier()))\n",
    "])\n",
    "\n",
    "ada_params = {\n",
    "    'tvec__max_df': [0.9, 0.95],\n",
    "    'tvec__ngram_range': [(1,1), (1, 2)],\n",
    "    'tvec__stop_words': [None, 'english'],\n",
    "    'ada__n_estimators': [50, 100],\n",
    "    'ada__base_estimator__max_depth': [1, 2],\n",
    "    'ada__learning_rate': [.9, 1.0],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(ada_tpipe, param_grid = ada_params, cv = 3)\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "26e08521-5862-43ea-90b1-9602da3caaf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test score: 0.6936507936507936\n",
      "F1 Score: 0.7165932452276065\n",
      "Precision Score: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "preds = gs.predict(X_test)\n",
    "print(f'test score: {gs.score(X_test, y_test)}')\n",
    "print(f'F1 Score: {f1_score(y_test, preds)}')\n",
    "print(f'Precision Score: {precision_score(y_test, preds)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f022f226-fd2f-4ca9-ad11-784acaf64fbe",
   "metadata": {},
   "source": [
    "*GradientBoostClassifier*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f8d419-5ad2-4ccb-94ce-d009f91673f8",
   "metadata": {},
   "source": [
    "#### 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "84a3b064-05f7-4684-b470-07c975767c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7639050815521404\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.95,\n",
       " 'cvec__ngram_range': (1, 2),\n",
       " 'cvec__stop_words': 'english',\n",
       " 'g__learning_rate': 0.9,\n",
       " 'g__n_estimators': 50}"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try with CountVectorizer\n",
    "g_cpipe = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('g', GradientBoostingClassifier())\n",
    "])\n",
    "\n",
    "ada_params = {\n",
    "    'cvec__max_df': [0.9, 0.95],\n",
    "    'cvec__ngram_range': [(1,1), (1, 2)],\n",
    "    'cvec__stop_words': [None, 'english'],\n",
    "    'g__n_estimators': [50, 100],\n",
    "    'g__learning_rate': [.9, 1.0],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(g_cpipe, param_grid = ada_params, cv = 3)\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "f044b541-ad33-407f-9bf9-c81fec143cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test score: 0.7428571428571429\n",
      "F1 Score: 0.7515337423312883\n",
      "Precision Score: 0.7270029673590505\n"
     ]
    }
   ],
   "source": [
    "preds = gs.predict(X_test)\n",
    "print(f'test score: {gs.score(X_test, y_test)}')\n",
    "print(f'F1 Score: {f1_score(y_test, preds)}')\n",
    "print(f'Precision Score: {precision_score(y_test, preds)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56d4f16-33f8-448e-a414-f038a1f9fd47",
   "metadata": {},
   "source": [
    "#### 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "cdadc2d7-45a7-4191-9ef5-9266576009b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7464388758506405\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'g__learning_rate': 0.9,\n",
       " 'g__n_estimators': 100,\n",
       " 'tvec__max_df': 0.9,\n",
       " 'tvec__ngram_range': (1, 1),\n",
       " 'tvec__stop_words': 'english'}"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try with Tfidf Vectorizer\n",
    "g_tpipe = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()),\n",
    "    ('g', GradientBoostingClassifier())\n",
    "])\n",
    "\n",
    "ada_params = {\n",
    "    'tvec__max_df': [0.9, 0.95],\n",
    "    'tvec__ngram_range': [(1,1), (1, 2)],\n",
    "    'tvec__stop_words': [None, 'english'],\n",
    "    'g__n_estimators': [50, 100],\n",
    "    'g__learning_rate': [.9, 1.0],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(g_tpipe, param_grid = ada_params, cv = 3)\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "c7e2abe6-cf19-4a3b-818a-2094eab3e635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test score: 0.7063492063492064\n",
      "F1 Score: 0.7412587412587412\n",
      "Precision Score: 0.6625\n"
     ]
    }
   ],
   "source": [
    "preds = gs.predict(X_test)\n",
    "print(f'test score: {gs.score(X_test, y_test)}')\n",
    "print(f'F1 Score: {f1_score(y_test, preds)}')\n",
    "print(f'Precision Score: {precision_score(y_test, preds)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfff562-af0e-469f-8036-a2e926636335",
   "metadata": {},
   "source": [
    "-------\n",
    "## Conclusions and next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34214ec-dbdb-463c-9731-264b23378530",
   "metadata": {},
   "source": [
    "We will plan to cast a wider net in this case by advertising on both the r/mlb and r/redsox, given we were not able to create a model that  accurately predict the correct subreddit at 80% (i.e. difficult to train a model that is able to discern between the two - so we'd rather cast a wider net across the subreddit channels. Despite not hitting the target accuracy and F1 scores of 80%, ran a sentiment analysis on the two subreddits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "d36c84ff-e8de-4e7a-83ce-b9b2d457ee02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Red Sox mean sentiment: 0.14174896825396827\n",
      "MLB mean sentiment: 0.2501284352660842\n"
     ]
    }
   ],
   "source": [
    "# Creat an instance of the Vader Sentiment Intensity Analyzer\n",
    "sent = SentimentIntensityAnalyzer()\n",
    "\n",
    "# slice the df to just include the specific subreddits\n",
    "redsox = reddit[reddit['subreddit'] == 1]\n",
    "mlb = reddit[reddit['subreddit'] == 0]\n",
    "\n",
    "# calculate the polarity score for each post and create a list of the compound scores that will provide average sentiment score\n",
    "print('Red Sox mean sentiment:',np.mean([sent.polarity_scores(i)['compound'] for i in redsox['selftext']]))\n",
    "print('MLB mean sentiment:',np.mean([sent.polarity_scores(i)['compound'] for i in mlb['selftext']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68173049-96d3-45b3-a2f3-cd9d3c6ce5e5",
   "metadata": {},
   "source": [
    "Both positive which is good to know - MLB may be more receptice to ads - and given how similar the sentiments are, makes the case to cast wider net by advertising "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi] *",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
